{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632667a1",
   "metadata": {
    "papermill": {
     "duration": 0.0122,
     "end_time": "2024-01-04T20:47:28.057204",
     "exception": false,
     "start_time": "2024-01-04T20:47:28.045004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border: 4px solid #4caf50; border-radius: 10px; padding: 20px; background-color: #e8f5e9; box-shadow: 0 4px 8px rgba(0,0,0,0.2);\">\n",
    "    <h1 style=\"text-align: center; color: #1b5e20; font-size: 28px; font-family: 'Arial', sans-serif; letter-spacing: 1px; text-shadow: 2px 2px 4px #a5d6a7;\">ENHANCED DRONE DETECTION SYSTEM WITH DEEP LEARNING</h1>\n",
    "    <h2 style=\"text-align: center; color: #1a237e; font-size: 22px; font-family: 'Arial', sans-serif; margin-top: 10px;\">Training a Faster RCNN X101 Detector</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4e6cb",
   "metadata": {
    "papermill": {
     "duration": 0.009592,
     "end_time": "2024-01-04T20:47:28.077279",
     "exception": false,
     "start_time": "2024-01-04T20:47:28.067687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"https://dronebelow.com/wp-content/uploads/2018/07/drones-artificial-intelligence.jpg\" alt=\"Drone ve Yapay Zeka\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc371739",
   "metadata": {
    "papermill": {
     "duration": 0.009489,
     "end_time": "2024-01-04T20:47:28.097345",
     "exception": false,
     "start_time": "2024-01-04T20:47:28.087856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border: 4px solid #ff9800; border-radius: 15px; padding: 20px; background-color: #f0f4c3; box-shadow: 0 4px 8px rgba(0,0,0,0.2);\">\n",
    "    <h2 style=\"text-align: left; color: #d32f2f; margin-bottom: 20px; font-size: 26px;\">Problem Statement</h2>\n",
    "    <p style=\"font-size: 16px; line-height: 1.6; color: #455a64;\">Military facilities are facing unauthorized reconnaissance and potential threats by Unmanned Aerial Vehicles (UAVs) or drones. These drones pose serious risks to privacy and security. Current security systems are inadequate in detecting these fast and small devices.</p>\n",
    "    <h2 style=\"text-align: left; color: #1976d2; margin-top: 30px; margin-bottom: 20px; font-size: 26px;\">Proposed Solution</h2>\n",
    "    <p style=\"font-size: 16px; line-height: 1.6; color: #455a64;\">An AI-based drone detection system developed using YOLO v4 and Faster R-CNN technologies. This system can detect drones in real-time around military facilities, track their locations, and quickly alert security teams. Thus, threats can be rapidly identified and necessary measures can be taken.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a403ba37",
   "metadata": {
    "papermill": {
     "duration": 0.009806,
     "end_time": "2024-01-04T20:47:28.117541",
     "exception": false,
     "start_time": "2024-01-04T20:47:28.107735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color: #3b3745; border-radius: 12px; padding: 20px; box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);\">\n",
    "    <h2 style=\"color: #F1A424; text-align: center;\">Table of Contents</h2>\n",
    "    <ul style=\"list-style: none; padding: 0;\">\n",
    "        <li><a href=\"#section-1\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">1.</span> Installation of Detectron2 and Loading Necessary Libraries</a></li>\n",
    "        <li><a href=\"#section-2\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">2.</span> Importing Detectron2 and Other Necessary Libraries</a></li>\n",
    "        <li><a href=\"#section-3\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">3.</span> Importing Basic Features of Detectron2</a></li>\n",
    "        <li><a href=\"#section-4\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">4.</span> Downloading and Saving the Dataset</a></li>\n",
    "        <li><a href=\"#section-5\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">5.</span> Visualizing the Training Dataset</a></li>\n",
    "        <li><a href=\"#section-6\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">6.</span> Training the Detectron2 Model</a></li>\n",
    "        <li><a href=\"#section-7\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">7.</span> Monitoring Model Performance with Tensorboard</a></li>\n",
    "        <li><a href=\"#section-8\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">8.</span> Evaluation and Inference on Test Data</a></li>\n",
    "        <li><a href=\"#section-9\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">9.</span> Cloning and Installing the Darknet Library</a></li>\n",
    "        <li><a href=\"#section-10\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">10.</span> Loading YOLO v4 Weights and Helper Functions</a></li>\n",
    "        <li><a href=\"#section-11\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">11.</span> Establishing Google Drive Connection and Creating Symbolic Links</a></li>\n",
    "        <li><a href=\"#section-12\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">12.</span> Copying and Opening Training and Test Datasets</a></li>\n",
    "        <li><a href=\"#section-13\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">13.</span> Preparing Configuration Files and Creating Training Datasets</a></li>\n",
    "        <li><a href=\"#section-14\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">14.</span> Downloading Pre-Trained Weights for Transfer Learning</a></li>\n",
    "        <li><a href=\"#section-15\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">15.</span> Training the Custom Detector and Visualizing Results</a></li>\n",
    "        <li><a href=\"#section-16\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">16.</span> Running the Custom Object Detector on Images and Videos</a></li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e550e6",
   "metadata": {
    "papermill": {
     "duration": 0.010049,
     "end_time": "2024-01-04T20:47:28.137369",
     "exception": false,
     "start_time": "2024-01-04T20:47:28.127320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-1\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>1 |</span></b> <b> Installation of Detectron2 and Loading Necessary Libraries</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f34c105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:47:28.161558Z",
     "iopub.status.busy": "2024-01-04T20:47:28.160657Z",
     "iopub.status.idle": "2024-01-04T20:48:25.812131Z",
     "shell.execute_reply": "2024-01-04T20:48:25.810381Z"
    },
    "papermill": {
     "duration": 57.667676,
     "end_time": "2024-01-04T20:48:25.815177",
     "exception": false,
     "start_time": "2024-01-04T20:47:28.147501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\r\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.5 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.5\u001b[0m\u001b[31m\r\n",
      "\u001b[0mRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (0.29.35)\r\n",
      "Collecting pyyaml==5.1\r\n",
      "  Downloading PyYAML-5.1.tar.gz (274 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\r\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.1-cp310-cp310-linux_x86_64.whl size=44091 sha256=5e3ae82cd93d236ce48e72b1c8773de22377c91fdb35c5ca056646ffc2f74330\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/70/83/31/975b737609aba39a4099d471d5684141c1fdc3404f97e7f68a\r\n",
      "Successfully built pyyaml\r\n",
      "Installing collected packages: pyyaml\r\n",
      "  Attempting uninstall: pyyaml\r\n",
      "    Found existing installation: PyYAML 6.0\r\n",
      "    Uninstalling PyYAML-6.0:\r\n",
      "      Successfully uninstalled PyYAML-6.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dask 2023.7.0 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\r\n",
      "distributed 2023.7.0 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\r\n",
      "flax 0.7.0 requires PyYAML>=5.4.1, but you have pyyaml 5.1 which is incompatible.\r\n",
      "jupyter-events 0.6.3 requires pyyaml>=5.3, but you have pyyaml 5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "kfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.0.1 requires PyYAML<7,>=5.3, but you have pyyaml 5.1 which is incompatible.\r\n",
      "kubernetes 26.1.0 requires pyyaml>=5.4.1, but you have pyyaml 5.1 which is incompatible.\r\n",
      "pytorch-lightning 2.0.4 requires PyYAML>=5.4, but you have pyyaml 5.1 which is incompatible.\r\n",
      "ydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed pyyaml-5.1\r\n",
      "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\r\n",
      "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-vitlwle5\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-vitlwle5\r\n",
      "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0) (59.8.0)\r\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0) (0.29.35)\r\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0) (3.7.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.40.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.23.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\r\n",
      "Building wheels for collected packages: pycocotools\r\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0-cp310-cp310-linux_x86_64.whl size=101559 sha256=607ac4599877cd39b26b3dba2ecf325e16d5085efdde7f6fdfd845da37bcfbb5\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rdx6af27/wheels/39/61/b4/480fbddb4d3d6bc34083e7397bc6f5d1381f79acc68e9f3511\r\n",
      "Successfully built pycocotools\r\n",
      "Installing collected packages: pycocotools\r\n",
      "Successfully installed pycocotools-2.0\r\n",
      "2.0.0+cpu False\n",
      "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\r\n",
      "Copyright (C) 2019 Free Software Foundation, Inc.\r\n",
      "This is free software; see the source for copying conditions.  There is NO\r\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n",
      "\r\n",
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\r\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement detectron2==0.1.3 (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for detectron2==0.1.3\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
    "!pip install cython pyyaml==5.1\n",
    "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version\n",
    "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d897cf3b",
   "metadata": {
    "papermill": {
     "duration": 0.013989,
     "end_time": "2024-01-04T20:48:25.843352",
     "exception": false,
     "start_time": "2024-01-04T20:48:25.829363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-2\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>2 |</span></b> <b> Importing Detectron2 and Other Necessary Libraries</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c8d87d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:48:25.876151Z",
     "iopub.status.busy": "2024-01-04T20:48:25.874691Z",
     "iopub.status.idle": "2024-01-04T20:48:26.397199Z",
     "shell.execute_reply": "2024-01-04T20:48:26.395801Z"
    },
    "papermill": {
     "duration": 0.541142,
     "end_time": "2024-01-04T20:48:26.399140",
     "exception": true,
     "start_time": "2024-01-04T20:48:25.857998",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'detectron2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_logger\n\u001b[1;32m      3\u001b[0m setup_logger()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'"
     ]
    }
   ],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4316f7d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-3\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>3 |</span></b> <b> Importing Basic Features of Detectron2</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba09e80",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f2219",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-4\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>4 |</span></b> <b>Downloading and Saving the Dataset</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b539c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -L \"https://app.roboflow.com/ds/zi9LUNojmz?key=H5YnroNUmG\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, \"/content/train/_annotations.coco.json\", \"/content/train\")\n",
    "register_coco_instances(\"my_dataset_val\", {}, \"/content/valid/_annotations.coco.json\", \"/content/valid\")\n",
    "register_coco_instances(\"my_dataset_test\", {}, \"/content/test/_annotations.coco.json\", \"/content/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104618a4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-5\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>5 |</span></b> <b>Visualizing the Training Dataset</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf5cf9c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2031e711",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-6\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>6 |</span></b> <b>Training the Detectron2 Model</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535062f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "    if output_folder is None:\n",
    "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "        output_folder = \"coco_eval\"\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "from detectron2.config import get_cfg\n",
    "import os\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\") \n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.MAX_ITER = 6000\n",
    "cfg.SOLVER.STEPS = (1000, 1500)\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe91fd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-7\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>7 |</span></b> <b>Monitoring Model Performance with Tensorboard</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca59c6d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a6443",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-8\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>8 |</span></b> <b>Evaluation and Inference on Test Data</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698f897",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_0004999.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"my_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "%ls ./output/\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "import glob\n",
    "for imageName in glob.glob('/content/test/*jpg'):\n",
    "  im = cv2.imread(imageName)\n",
    "  outputs = predictor(im)\n",
    "  v = Visualizer(im[:, :, ::-1], metadata=test_metadata, scale=0.8)\n",
    "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "  cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef09c3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-9\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>9 |</span></b> <b>Cloning and Installing the Darknet Library</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb019481",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clone darknet repo\n",
    "!git clone https://github.com/AlexeyAB/darknet\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "%cd darknet\n",
    "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
    "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
    "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1285ea3b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-10\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>10 |</span></b> <b>Loading YOLO v4 Weights and Helper Functions</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afbe90",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b10e3d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imShow(path):\n",
    "  import cv2\n",
    "  import matplotlib.pyplot as plt\n",
    "  %matplotlib inline\n",
    "\n",
    "  image = cv2.imread(path)\n",
    "  height, width = image.shape[:2]\n",
    "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(18, 10)\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd544e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload():\n",
    "  from google.colab import files\n",
    "  uploaded = files.upload() \n",
    "  for name, data in uploaded.items():\n",
    "    with open(name, 'wb') as f:\n",
    "      f.write(data)\n",
    "      print ('saved file', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a76147",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download(path):\n",
    "  from google.colab import files\n",
    "  files.download(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b690df34",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-11\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>11 |</span></b> <b>Establishing Google Drive Connection and Creating Symbolic Links</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402349c9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd ..\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
    "!ls /mydrive\n",
    "\n",
    "%cd darknet\n",
    "!ls /mydrive/yolov4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b766b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-12\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>12 |</span></b> <b>Copying and Opening Training and Test Datasets</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d428ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /mydrive/yolov4/obj.zip ../\n",
    "!cp /mydrive/yolov4/test.zip ../\n",
    "!unzip ../obj.zip -d data/\n",
    "!unzip ../test.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ee110",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-13\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>13 |</span></b> <b>Preparing Configuration Files and Creating Training Datasets</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce0ee8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp cfg/yolov4-custom.cfg /mydrive/yolov4/yolov4-obj.cfg\n",
    "download('cfg/yolov4-custom.cfg')\n",
    "!cp /mydrive/yolov4/yolov4-obj.cfg ./cfg\n",
    "!cp /mydrive/yolov4/obj.names ./data\n",
    "!cp /mydrive/yolov4/obj.data  ./data\n",
    "!cp /mydrive/yolov4/generate_train.py ./\n",
    "!cp /mydrive/yolov4/generate_test.py ./\n",
    "!python generate_train.py\n",
    "!python generate_test.py\n",
    "!ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143c180",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-14\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>14 |</span></b> <b>Downloading Pre-Trained Weights for Transfer Learning</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1090494",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7534a4d1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-15\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>15 |</span></b> <b>Training the Custom Detector and Visualizing Results</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ee18f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./darknet detector train data/obj.data cfg/yolov4-obj.cfg yolov4.conv.137 -dont_show -map\n",
    "imShow('chart.png')\n",
    "!./darknet detector train data/obj.data cfg/yolov4-obj.cfg /mydrive/yolov4/backup/yolov4-obj_last.weights -dont_show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce07ec02",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-16\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>16 |</span></b> <b>Running the Custom Object Detector on Images and Videos</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d792dfb6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd cfg\n",
    "!sed -i 's/batch=64/batch=1/' yolov4-obj.cfg\n",
    "!sed -i 's/subdivisions=16/subdivisions=1/' yolov4-obj.cfg\n",
    "%cd ..\n",
    "!./darknet detector test data/obj.data cfg/yolov4-obj.cfg /mydrive/yolov4/backup/yolov4-obj_last.weights /mydrive/images/UAV8.jpg -thresh 0.3\n",
    "imShow('predictions.jpg')\n",
    "\n",
    "!./darknet detector demo data/obj.data cfg/yolov4-obj.cfg /mydrive/yolov4/backup/yolov4-obj_last.weights -dont_show /mydrive/videos/UAV3.mp4 -i 0 -out_filename /mydrive/videos/results3.avi"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 1452811,
     "sourceId": 22040,
     "sourceType": "competition"
    },
    {
     "datasetId": 32843,
     "sourceId": 48230,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 357542,
     "sourceId": 715382,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30527,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 73.921884,
   "end_time": "2024-01-04T20:48:28.040711",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-04T20:47:14.118827",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
